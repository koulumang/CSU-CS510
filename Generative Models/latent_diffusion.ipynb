{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hDpUvZQ_6DgU"
      },
      "source": [
        "## Latent space with Stable Diffusion\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gte5XrjR6DgW"
      },
      "source": [
        "### Overview\n",
        "\n",
        "\n",
        "![The Stable Diffusion architecture](https://i.imgur.com/2uC8rYJ.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSlUBLob6DgY",
        "outputId": "0a9a1ca0-83d2-4b97-823b-f3ee9b187bbb"
      },
      "outputs": [],
      "source": [
        "# pip install tensorflow keras_cv --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Ba0V-T6Dgc",
        "outputId": "225b8ef0-9676-4d06-f9aa-e940db10028a"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'builder' from 'google.protobuf.internal' (/s/chopin/l/grad/ukoul/.local/lib/python3.9/site-packages/google/protobuf/internal/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m/s/chopin/l/grad/ukoul/CSU-CS510/Generative Models/latent_diffusion.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsaturn.cs.colostate.edu/s/chopin/l/grad/ukoul/CSU-CS510/Generative%20Models/latent_diffusion.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras_cv\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsaturn.cs.colostate.edu/s/chopin/l/grad/ukoul/CSU-CS510/Generative%20Models/latent_diffusion.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsaturn.cs.colostate.edu/s/chopin/l/grad/ukoul/CSU-CS510/Generative%20Models/latent_diffusion.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras_cv/__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m# isort:on\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_cv\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_cv\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_cv\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_cv\u001b[39;00m \u001b[39mimport\u001b[39;00m losses\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras_cv/datasets/__init__.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2022 The KerasCV Authors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_cv\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m pascal_voc\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras_cv/datasets/pascal_voc/__init__.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2022 The KerasCV Authors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_cv\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpascal_voc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mload\u001b[39;00m \u001b[39mimport\u001b[39;00m load\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras_cv/datasets/pascal_voc/load.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2022 The KerasCV Authors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfds\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_cv\u001b[39;00m \u001b[39mimport\u001b[39;00m bounding_box\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcurry_map_function\u001b[39m(bounding_box_format):\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/__init__.py:43\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m _TIMESTAMP_IMPORT_STARTS \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabsl\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[0;32m---> 43\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogging\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_tfds_logging\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogging\u001b[39;00m \u001b[39mimport\u001b[39;00m call_metadata \u001b[39mas\u001b[39;00m _call_metadata\n\u001b[1;32m     46\u001b[0m _metadata \u001b[39m=\u001b[39m _call_metadata\u001b[39m.\u001b[39mCallMetadata()\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/core/__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m# Allow to use `tfds.core.Path` in dataset implementation which seems more\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m# natural than having to import a third party module.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39metils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mepath\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m community\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_builder\u001b[39;00m \u001b[39mimport\u001b[39;00m BeamBasedBuilder\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_builder\u001b[39;00m \u001b[39mimport\u001b[39;00m BuilderConfig\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/core/community/__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# coding=utf-8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Copyright 2023 The TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m\"\"\"Community dataset API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommunity\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhuggingface_wrapper\u001b[39;00m \u001b[39mimport\u001b[39;00m mock_builtin_to_use_gfile\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommunity\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhuggingface_wrapper\u001b[39;00m \u001b[39mimport\u001b[39;00m mock_huggingface_import\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommunity\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mload\u001b[39;00m \u001b[39mimport\u001b[39;00m builder_cls_from_module\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/core/community/huggingface_wrapper.py:31\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39munittest\u001b[39;00m \u001b[39mimport\u001b[39;00m mock\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39metils\u001b[39;00m \u001b[39mimport\u001b[39;00m epath\n\u001b[0;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m dataset_builder\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m dataset_info\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m download\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39metils\u001b[39;00m \u001b[39mimport\u001b[39;00m epath\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m constants\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m dataset_info\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m dataset_metadata\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m decode\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py:50\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m lazy_imports_lib\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m naming\n\u001b[0;32m---> 50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m splits \u001b[39mas\u001b[39;00m splits_lib\n\u001b[1;32m     51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[1;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeatures\u001b[39;00m \u001b[39mimport\u001b[39;00m feature \u001b[39mas\u001b[39;00m feature_lib\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/core/splits.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39metils\u001b[39;00m \u001b[39mimport\u001b[39;00m epath\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m naming\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m proto \u001b[39mas\u001b[39;00m proto_lib\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m units\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/core/proto/__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# coding=utf-8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Copyright 2023 The TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m\"\"\"Public API of the proto package.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m dataset_info_generated_pb2 \u001b[39mas\u001b[39;00m dataset_info_pb2  \u001b[39m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_generated_pb2 \u001b[39mas\u001b[39;00m feature_pb2  \u001b[39m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[1;32m     21\u001b[0m SplitInfo \u001b[39m=\u001b[39m dataset_info_pb2\u001b[39m.\u001b[39mSplitInfo\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow_datasets/core/proto/dataset_info_generated_pb2.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# coding=utf-8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Copyright 2023 The TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m# Generated by the protocol buffer compiler.  DO NOT EDIT!\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# source: dataset_info.proto\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m\"\"\"Generated protocol buffer code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minternal\u001b[39;00m \u001b[39mimport\u001b[39;00m builder \u001b[39mas\u001b[39;00m _builder\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m descriptor \u001b[39mas\u001b[39;00m _descriptor\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m descriptor_pool \u001b[39mas\u001b[39;00m _descriptor_pool\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'builder' from 'google.protobuf.internal' (/s/chopin/l/grad/ukoul/.local/lib/python3.9/site-packages/google/protobuf/internal/__init__.py)"
          ]
        }
      ],
      "source": [
        "import keras_cv\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "from PIL import Image\n",
        "\n",
        "# Enable mixed precision\n",
        "# (only do this if you have a recent NVIDIA GPU)\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# Instantiate the Stable Diffusion model\n",
        "model = keras_cv.models.StableDiffusion(jit_compile=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "secdYXpF6Dgd"
      },
      "source": [
        "## Interpolating between text prompts\n",
        "\n",
        "In Stable Diffusion, a text prompt is first encoded into a vector,\n",
        "and that encoding is used to guide the diffusion process.\n",
        "The latent encoding vector has shape\n",
        "77x768 (that's huge!), and when we give Stable Diffusion a text prompt, we're\n",
        "generating images from just one such point on the latent manifold.\n",
        "\n",
        "To explore more of this manifold, we can interpolate between two text encodings\n",
        "and generate images at those interpolated points:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwF6kwW06Dgg",
        "outputId": "cc4a9857-b906-4942-a5c2-15214f045619"
      },
      "outputs": [],
      "source": [
        "# prompt_1 = \"Student Coding on Macbook laptop\"\n",
        "# prompt_2 = \"Neural Network being taught by professor\"\n",
        "prompt_1 = \"Donald Trump and Joe Biden are friends\"\n",
        "prompt_2 = \"Donald Trump and Joe Biden are enemies\"\n",
        "\n",
        "interpolation_steps = 5\n",
        "\n",
        "encoding_1 = tf.squeeze(model.encode_text(prompt_1))\n",
        "encoding_2 = tf.squeeze(model.encode_text(prompt_2))\n",
        "\n",
        "\n",
        "interpolated_encodings = tf.linspace(encoding_1, encoding_2, interpolation_steps)\n",
        "\n",
        "# Show the size of the latent manifold\n",
        "print(f\"Encoding shape: {encoding_1.shape}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8LgW2RGe6Dgj"
      },
      "source": [
        "Once we've interpolated the encodings, we can generate images from each point.\n",
        "Note that in order to maintain some stability between the resulting images we\n",
        "keep the diffusion noise constant between images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdLUQVLg6Dgj",
        "outputId": "a55ed2be-49e0-4dbf-8f00-ae93274d8941"
      },
      "outputs": [],
      "source": [
        "seed = 12345\n",
        "noise = tf.random.normal((512 // 8, 512 // 8, 4), seed=seed)\n",
        "\n",
        "images = model.generate_image(\n",
        "    interpolated_encodings,\n",
        "    batch_size=interpolation_steps,\n",
        "    diffusion_noise=noise,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V7HNDRT6Dgm"
      },
      "outputs": [],
      "source": [
        "\n",
        "def export_as_gif(filename, images, frames_per_second=10, rubber_band=False):\n",
        "    if rubber_band:\n",
        "        images += images[2:-1][::-1]\n",
        "    images[0].save(\n",
        "        filename,\n",
        "        save_all=True,\n",
        "        append_images=images[1:],\n",
        "        duration=1000 // frames_per_second,\n",
        "        loop=0,\n",
        "    )\n",
        "print('total images generated :',len(images))\n",
        "\n",
        "for i in range(len(images)):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.imshow(images[i],cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "export_as_gif(\n",
        "    \"CSU+iphone.gif\",\n",
        "    [Image.fromarray(img) for img in images],\n",
        "    frames_per_second=1,\n",
        "    rubber_band=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnGN3OwH6Dgn"
      },
      "outputs": [],
      "source": [
        "interpolation_steps = 150\n",
        "batch_size = 3\n",
        "batches = interpolation_steps // batch_size\n",
        "\n",
        "interpolated_encodings = tf.linspace(encoding_1, encoding_2, interpolation_steps)\n",
        "batched_encodings = tf.split(interpolated_encodings, batches)\n",
        "\n",
        "images = []\n",
        "for batch in range(batches):\n",
        "    images += [\n",
        "        Image.fromarray(img)\n",
        "        for img in model.generate_image(\n",
        "            batched_encodings[batch],\n",
        "            batch_size=batch_size,\n",
        "            num_steps=25,\n",
        "            diffusion_noise=noise,\n",
        "        )\n",
        "    ]\n",
        "\n",
        "export_as_gif(\"Trump+Biden.gif\", images, rubber_band=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RKDS1H2t6Dgn"
      },
      "source": [
        "\n",
        "\n",
        "We can even extend this concept for more than one image. For example, we can\n",
        "interpolate between four prompts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "367C1Nal6Dgn"
      },
      "outputs": [],
      "source": [
        "prompt_1 = \"Student Coding on Macbook\"\n",
        "prompt_2 = \"Neural Network being taught by professor\"\n",
        "prompt_3 = \"painting of colorado state university\"\n",
        "prompt_4 = \"Futuristic picture of Kashmir\"\n",
        "\n",
        "interpolation_steps = 6\n",
        "batch_size = 3\n",
        "batches = (interpolation_steps**2) // batch_size\n",
        "\n",
        "encoding_1 = tf.squeeze(model.encode_text(prompt_1))\n",
        "encoding_2 = tf.squeeze(model.encode_text(prompt_2))\n",
        "encoding_3 = tf.squeeze(model.encode_text(prompt_3))\n",
        "encoding_4 = tf.squeeze(model.encode_text(prompt_4))\n",
        "\n",
        "interpolated_encodings = tf.linspace(\n",
        "    tf.linspace(encoding_1, encoding_2, interpolation_steps),\n",
        "    tf.linspace(encoding_3, encoding_4, interpolation_steps),\n",
        "    interpolation_steps,\n",
        ")\n",
        "interpolated_encodings = tf.reshape(\n",
        "    interpolated_encodings, (interpolation_steps**2, 77, 768)\n",
        ")\n",
        "batched_encodings = tf.split(interpolated_encodings, batches)\n",
        "\n",
        "images = []\n",
        "for batch in range(batches):\n",
        "    images.append(\n",
        "        model.generate_image(\n",
        "            batched_encodings[batch],\n",
        "            batch_size=batch_size,\n",
        "            diffusion_noise=noise,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_grid(\n",
        "    images,\n",
        "    path,\n",
        "    grid_size,\n",
        "    scale=2,\n",
        "):\n",
        "    fig = plt.figure(figsize=(grid_size * scale, grid_size * scale))\n",
        "    fig.tight_layout()\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.margins(x=0, y=0)\n",
        "    plt.axis(\"off\")\n",
        "    images = images.astype(int)\n",
        "    for row in range(grid_size):\n",
        "        for col in range(grid_size):\n",
        "            index = row * grid_size + col\n",
        "            plt.subplot(grid_size, grid_size, index + 1)\n",
        "            plt.imshow(images[index].astype(\"uint8\"))\n",
        "            plt.axis(\"off\")\n",
        "            plt.margins(x=0, y=0)\n",
        "    plt.savefig(\n",
        "        fname=path,\n",
        "        pad_inches=0,\n",
        "        bbox_inches=\"tight\",\n",
        "        transparent=False,\n",
        "        dpi=60,\n",
        "    )\n",
        "\n",
        "\n",
        "images = np.concatenate(images)\n",
        "plot_grid(images, \"4-way-interpolation.jpg\", interpolation_steps)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "random_walks_with_stable_diffusion",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
