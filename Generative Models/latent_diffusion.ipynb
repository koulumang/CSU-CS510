{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hDpUvZQ_6DgU"
      },
      "source": [
        "## Latent space with Stable Diffusion\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gte5XrjR6DgW"
      },
      "source": [
        "### Overview\n",
        "\n",
        "\n",
        "![The Stable Diffusion architecture](https://i.imgur.com/2uC8rYJ.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSlUBLob6DgY",
        "outputId": "0a9a1ca0-83d2-4b97-823b-f3ee9b187bbb"
      },
      "outputs": [],
      "source": [
        "# pip install tensorflow keras_cv --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Ba0V-T6Dgc",
        "outputId": "225b8ef0-9676-4d06-f9aa-e940db10028a"
      },
      "outputs": [],
      "source": [
        "import keras_cv\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "from PIL import Image\n",
        "\n",
        "# Enable mixed precision\n",
        "# (only do this if you have a recent NVIDIA GPU)\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# Instantiate the Stable Diffusion model\n",
        "model = keras_cv.models.StableDiffusion(jit_compile=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "secdYXpF6Dgd"
      },
      "source": [
        "## Interpolating between text prompts\n",
        "\n",
        "In Stable Diffusion, a text prompt is first encoded into a vector,\n",
        "and that encoding is used to guide the diffusion process.\n",
        "The latent encoding vector has shape\n",
        "77x768 (that's huge!), and when we give Stable Diffusion a text prompt, we're\n",
        "generating images from just one such point on the latent manifold.\n",
        "\n",
        "To explore more of this manifold, we can interpolate between two text encodings\n",
        "and generate images at those interpolated points:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwF6kwW06Dgg",
        "outputId": "cc4a9857-b906-4942-a5c2-15214f045619"
      },
      "outputs": [],
      "source": [
        "# prompt_1 = \"Student Coding on Macbook laptop\"\n",
        "# prompt_2 = \"Neural Network being taught by professor\"\n",
        "prompt_1 = \"Donald Trump and Joe Biden are friends\"\n",
        "prompt_2 = \"Donald Trump and Joe Biden are enemies\"\n",
        "\n",
        "interpolation_steps = 5\n",
        "\n",
        "encoding_1 = tf.squeeze(model.encode_text(prompt_1))\n",
        "encoding_2 = tf.squeeze(model.encode_text(prompt_2))\n",
        "\n",
        "\n",
        "interpolated_encodings = tf.linspace(encoding_1, encoding_2, interpolation_steps)\n",
        "\n",
        "# Show the size of the latent manifold\n",
        "print(f\"Encoding shape: {encoding_1.shape}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8LgW2RGe6Dgj"
      },
      "source": [
        "Once we've interpolated the encodings, we can generate images from each point.\n",
        "Note that in order to maintain some stability between the resulting images we\n",
        "keep the diffusion noise constant between images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdLUQVLg6Dgj",
        "outputId": "a55ed2be-49e0-4dbf-8f00-ae93274d8941"
      },
      "outputs": [],
      "source": [
        "seed = 12345\n",
        "noise = tf.random.normal((512 // 8, 512 // 8, 4), seed=seed)\n",
        "\n",
        "images = model.generate_image(\n",
        "    interpolated_encodings,\n",
        "    batch_size=interpolation_steps,\n",
        "    diffusion_noise=noise,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V7HNDRT6Dgm"
      },
      "outputs": [],
      "source": [
        "\n",
        "def export_as_gif(filename, images, frames_per_second=10, rubber_band=False):\n",
        "    if rubber_band:\n",
        "        images += images[2:-1][::-1]\n",
        "    images[0].save(\n",
        "        filename,\n",
        "        save_all=True,\n",
        "        append_images=images[1:],\n",
        "        duration=1000 // frames_per_second,\n",
        "        loop=0,\n",
        "    )\n",
        "print('total images generated :',len(images))\n",
        "\n",
        "for i in range(len(images)):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.imshow(images[i],cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "export_as_gif(\n",
        "    \"CSU+iphone.gif\",\n",
        "    [Image.fromarray(img) for img in images],\n",
        "    frames_per_second=1,\n",
        "    rubber_band=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnGN3OwH6Dgn"
      },
      "outputs": [],
      "source": [
        "interpolation_steps = 150\n",
        "batch_size = 3\n",
        "batches = interpolation_steps // batch_size\n",
        "\n",
        "interpolated_encodings = tf.linspace(encoding_1, encoding_2, interpolation_steps)\n",
        "batched_encodings = tf.split(interpolated_encodings, batches)\n",
        "\n",
        "images = []\n",
        "for batch in range(batches):\n",
        "    images += [\n",
        "        Image.fromarray(img)\n",
        "        for img in model.generate_image(\n",
        "            batched_encodings[batch],\n",
        "            batch_size=batch_size,\n",
        "            num_steps=25,\n",
        "            diffusion_noise=noise,\n",
        "        )\n",
        "    ]\n",
        "\n",
        "export_as_gif(\"Trump+Biden.gif\", images, rubber_band=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RKDS1H2t6Dgn"
      },
      "source": [
        "\n",
        "\n",
        "We can even extend this concept for more than one image. For example, we can\n",
        "interpolate between four prompts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "367C1Nal6Dgn"
      },
      "outputs": [],
      "source": [
        "prompt_1 = \"Student Coding on Macbook\"\n",
        "prompt_2 = \"Neural Network being taught by professor\"\n",
        "prompt_3 = \"painting of colorado state university\"\n",
        "prompt_4 = \"Futuristic picture of Kashmir\"\n",
        "\n",
        "interpolation_steps = 6\n",
        "batch_size = 3\n",
        "batches = (interpolation_steps**2) // batch_size\n",
        "\n",
        "encoding_1 = tf.squeeze(model.encode_text(prompt_1))\n",
        "encoding_2 = tf.squeeze(model.encode_text(prompt_2))\n",
        "encoding_3 = tf.squeeze(model.encode_text(prompt_3))\n",
        "encoding_4 = tf.squeeze(model.encode_text(prompt_4))\n",
        "\n",
        "interpolated_encodings = tf.linspace(\n",
        "    tf.linspace(encoding_1, encoding_2, interpolation_steps),\n",
        "    tf.linspace(encoding_3, encoding_4, interpolation_steps),\n",
        "    interpolation_steps,\n",
        ")\n",
        "interpolated_encodings = tf.reshape(\n",
        "    interpolated_encodings, (interpolation_steps**2, 77, 768)\n",
        ")\n",
        "batched_encodings = tf.split(interpolated_encodings, batches)\n",
        "\n",
        "images = []\n",
        "for batch in range(batches):\n",
        "    images.append(\n",
        "        model.generate_image(\n",
        "            batched_encodings[batch],\n",
        "            batch_size=batch_size,\n",
        "            diffusion_noise=noise,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_grid(\n",
        "    images,\n",
        "    path,\n",
        "    grid_size,\n",
        "    scale=2,\n",
        "):\n",
        "    fig = plt.figure(figsize=(grid_size * scale, grid_size * scale))\n",
        "    fig.tight_layout()\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.margins(x=0, y=0)\n",
        "    plt.axis(\"off\")\n",
        "    images = images.astype(int)\n",
        "    for row in range(grid_size):\n",
        "        for col in range(grid_size):\n",
        "            index = row * grid_size + col\n",
        "            plt.subplot(grid_size, grid_size, index + 1)\n",
        "            plt.imshow(images[index].astype(\"uint8\"))\n",
        "            plt.axis(\"off\")\n",
        "            plt.margins(x=0, y=0)\n",
        "    plt.savefig(\n",
        "        fname=path,\n",
        "        pad_inches=0,\n",
        "        bbox_inches=\"tight\",\n",
        "        transparent=False,\n",
        "        dpi=60,\n",
        "    )\n",
        "\n",
        "\n",
        "images = np.concatenate(images)\n",
        "plot_grid(images, \"4-way-interpolation.jpg\", interpolation_steps)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "random_walks_with_stable_diffusion",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
